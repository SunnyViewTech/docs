"use strict";(self.webpackChunkmy_website_en_2=self.webpackChunkmy_website_en_2||[]).push([[3810],{3:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>d,toc:()=>l});var i=n(4848),a=n(8453);const s={sidebar_position:90,title:"SDK Guide",slug:"/sdk-guide"},r="Dollars Markerless MoCap SDK Guide",d={id:"Integration/sdk_guide",title:"SDK Guide",description:"Introduction",source:"@site/docs/Integration/sdk_guide.md",sourceDirName:"Integration",slug:"/sdk-guide",permalink:"/sdk-guide",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:90,frontMatter:{sidebar_position:90,title:"SDK Guide",slug:"/sdk-guide"},sidebar:"tutorialSidebar",previous:{title:"Start Using Dollars MoCap SDK",permalink:"/sdk"},next:{title:"FAQ",permalink:"/faq"}},o={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Data types",id:"data-types",level:2},{value:"Dollars.MoCapMode",id:"dollarsmocapmode",level:3},{value:"Dollars.DominantEye",id:"dollarsdominanteye",level:3},{value:"Sensitivity",id:"sensitivity",level:3},{value:"Strength",id:"strength",level:3},{value:"Classes",id:"classes",level:2},{value:"AvatarBody",id:"avatarbody",level:3},{value:"InitFilter(int sensitivity)",id:"initfilterint-sensitivity",level:4},{value:"SetMoCapMode(Dollars.MoCapMode mode)",id:"setmocapmodedollarsmocapmode-mode",level:4},{value:"SetSensitivity(int sensitivity)",id:"setsensitivityint-sensitivity",level:4},{value:"Calibrate()",id:"calibrate",level:4},{value:"ResetCalibration()",id:"resetcalibration",level:4},{value:"AvatarFace",id:"avatarface",level:3},{value:"Calibrate()",id:"calibrate-1",level:4},{value:"ResetCalibration()",id:"resetcalibration-1",level:4},{value:"SetStrength(float strength)",id:"setstrengthfloat-strength",level:4},{value:"SetDominantEye(Dollars.DominantEye eye)",id:"setdominanteyedollarsdominanteye-eye",level:4},{value:"How to Use",id:"how-to-use",level:2},{value:"Conventions",id:"conventions",level:3},{value:"Add Motion Capture to an Avatar",id:"add-motion-capture-to-an-avatar",level:3},{value:"Add Face Capture to an Avatar",id:"add-face-capture-to-an-avatar",level:3}];function c(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"dollars-markerless-mocap-sdk-guide",children:"Dollars Markerless MoCap SDK Guide"})}),"\n",(0,i.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsxs)(t.p,{children:["This SDK is based on the ",(0,i.jsx)(t.a,{href:"https://github.com/homuler/MediaPipeUnityPlugin",children:"MediaPipeUnityPlugin"})," project and runs on Unity platforms other besides WebGL."]}),"\n",(0,i.jsx)(t.h2,{id:"data-types",children:"Data types"}),"\n",(0,i.jsx)(t.h3,{id:"dollarsmocapmode",children:"Dollars.MoCapMode"}),"\n",(0,i.jsx)(t.p,{children:"MoCap Mode"}),"\n",(0,i.jsx)(t.p,{children:"Type: Enumeration\nValues: jump, flat, upperbody"}),"\n",(0,i.jsx)(t.h3,{id:"dollarsdominanteye",children:"Dollars.DominantEye"}),"\n",(0,i.jsx)(t.p,{children:"DominantEye in Facial Capture"}),"\n",(0,i.jsx)(t.p,{children:"Type: Enumeration\nValues: none, left, right"}),"\n",(0,i.jsx)(t.h3,{id:"sensitivity",children:"Sensitivity"}),"\n",(0,i.jsx)(t.p,{children:"Sensitivity of Motion Capture"}),"\n",(0,i.jsx)(t.p,{children:"Type: Integer\nValues: 1-5, 1 is the most stable, 5 is the most sensitive"}),"\n",(0,i.jsx)(t.h3,{id:"strength",children:"Strength"}),"\n",(0,i.jsx)(t.p,{children:"Strength of Facial Capture"}),"\n",(0,i.jsx)(t.p,{children:"Type: Float\nValues: Unrestricted, but a range between 0.5 to 2 is recommended, 1 is the default"}),"\n",(0,i.jsx)(t.h2,{id:"classes",children:"Classes"}),"\n",(0,i.jsx)(t.h3,{id:"avatarbody",children:"AvatarBody"}),"\n",(0,i.jsx)(t.p,{children:"Used for calculating skeletal data"}),"\n",(0,i.jsx)(t.h4,{id:"initfilterint-sensitivity",children:"InitFilter(int sensitivity)"}),"\n",(0,i.jsx)(t.h4,{id:"setmocapmodedollarsmocapmode-mode",children:"SetMoCapMode(Dollars.MoCapMode mode)"}),"\n",(0,i.jsx)(t.h4,{id:"setsensitivityint-sensitivity",children:"SetSensitivity(int sensitivity)"}),"\n",(0,i.jsx)(t.h4,{id:"calibrate",children:"Calibrate()"}),"\n",(0,i.jsx)(t.p,{children:"Description:"}),"\n",(0,i.jsx)(t.p,{children:"Based on the current output of MediaPipe, adjust the avatar to stand upright with both feet on the ground."}),"\n",(0,i.jsx)(t.p,{children:"MediaPipe's human body will be tilted forward (see below), the degree of tilt varies depending on the camera parameters, the size of the person, etc."}),"\n",(0,i.jsx)(t.p,{children:"Therefore, it is recommended to perform a calibration before starting in order to achieve better motion capture results."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(397).A+"",width:"1540",height:"1368"})}),"\n",(0,i.jsx)(t.p,{children:"Just relax and look ahead while calibrating."}),"\n",(0,i.jsx)(t.h4,{id:"resetcalibration",children:"ResetCalibration()"}),"\n",(0,i.jsx)(t.p,{children:"Description:"}),"\n",(0,i.jsx)(t.p,{children:"Used to reset the calibration data, recommended to be called when changing cameras as well as video files."}),"\n",(0,i.jsx)(t.h3,{id:"avatarface",children:"AvatarFace"}),"\n",(0,i.jsx)(t.p,{children:"Used to get face capture data"}),"\n",(0,i.jsx)(t.h4,{id:"calibrate-1",children:"Calibrate()"}),"\n",(0,i.jsx)(t.p,{children:"Description:"}),"\n",(0,i.jsx)(t.p,{children:"Use current face capture expression parameters as a baseline"}),"\n",(0,i.jsx)(t.h4,{id:"resetcalibration-1",children:"ResetCalibration()"}),"\n",(0,i.jsx)(t.p,{children:"Description:"}),"\n",(0,i.jsx)(t.p,{children:"Used to reset the facial calibration data.\nRecommended to be called at the same time as AvatarBody.ResetCalibration()."}),"\n",(0,i.jsx)(t.h4,{id:"setstrengthfloat-strength",children:"SetStrength(float strength)"}),"\n",(0,i.jsx)(t.p,{children:"Description:"}),"\n",(0,i.jsx)(t.p,{children:"Set the strength of facial capture"}),"\n",(0,i.jsx)(t.h4,{id:"setdominanteyedollarsdominanteye-eye",children:"SetDominantEye(Dollars.DominantEye eye)"}),"\n",(0,i.jsx)(t.p,{children:"Description:"}),"\n",(0,i.jsx)(t.p,{children:"Set the dominant eye in facial capture"}),"\n",(0,i.jsx)(t.h2,{id:"how-to-use",children:"How to Use"}),"\n",(0,i.jsx)(t.h3,{id:"conventions",children:"Conventions"}),"\n",(0,i.jsx)(t.p,{children:"Please call the functions below before starting mocap,"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"AvatarBody.InitFilter(5);"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"AvatarBody.SetMoCapMode(MoCapMode.jump);"})}),"\n",(0,i.jsx)(t.p,{children:"This will initialize the filter and set the motion capture mode, the order cannot be changed."}),"\n",(0,i.jsx)(t.p,{children:"You can use MoCapManager.cs in the example project as a reference."}),"\n",(0,i.jsx)(t.p,{children:"Additionally, ensure that MoCapManager.cs is executed before any motion capture-related code by specifying the execution order."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(9103).A+"",width:"1570",height:"957"})}),"\n",(0,i.jsx)(t.p,{children:"Please keep the order in the screenshot above for motion capture related codes."}),"\n",(0,i.jsx)(t.h3,{id:"add-motion-capture-to-an-avatar",children:"Add Motion Capture to an Avatar"}),"\n",(0,i.jsx)(t.p,{children:"Set the model's Rig to Humanoid and ensure all bones are correctly configured"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(7624).A+"",width:"1870",height:"946"})}),"\n",(0,i.jsx)(t.p,{children:"Add the model to the scene and attach a MoCapSrc component"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(1984).A+"",width:"1950",height:"1372"})}),"\n",(0,i.jsx)(t.p,{children:"If the model is not in a TPose, adjust the bone angles to set the model into a TPose."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(9770).A+"",width:"2000",height:"775"})}),"\n",(0,i.jsx)(t.p,{children:"In the MoCapSrc component, set the src variable to the MoCap object in the scene"}),"\n",(0,i.jsx)(t.p,{children:"Done!"}),"\n",(0,i.jsx)(t.h3,{id:"add-face-capture-to-an-avatar",children:"Add Face Capture to an Avatar"}),"\n",(0,i.jsx)(t.p,{children:"Add the Face Cap Controller component to the avatar, and set its Fcr variable to the robotDAC under MoCap in the scene"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(1829).A+"",width:"2000",height:"561"})}),"\n",(0,i.jsx)(t.p,{children:"Create a Face Capture Mapping file"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(204).A+"",width:"2000",height:"694"})}),"\n",(0,i.jsx)(t.p,{children:"In the 'To' column of the Mapping file, fill in the names of the blendshapes corresponding to each facial capture expression, paying attention to case sensitivity."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(887).A+"",width:"2000",height:"972"})}),"\n",(0,i.jsx)(t.p,{children:"In the Skinned Mesh Renderers array of the Face Capture Controller, enter the avatars meshes with blendshapes."}),"\n",(0,i.jsx)(t.p,{children:"In the Mapping array, fill in the mapping files"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(5102).A+"",width:"1210",height:"506"})}),"\n",(0,i.jsx)(t.p,{children:"Notes:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"If there is no blendshape corresponding to a certain facial capture expression, leave the corresponding position in the mapping file empty."}),"\n",(0,i.jsx)(t.li,{children:"The TongueOut column and those that follow in the mapping file can be ignored."}),"\n",(0,i.jsx)(t.li,{children:"If you need to use the same facial capture expression to control multiple blendshapes, you can add the same mesh multiple times to the Skinned Mesh Renderers array and correspond them to different mappings."}),"\n",(0,i.jsx)(t.li,{children:"The lengths and orders of the Skinned Mesh Renderers and Mappings arrays need to be the same."}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},9103:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/execution-fae1ddec9b2a5949bc380a3eca3a86e7.png"},397:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/mediapipe-245a706ed66a1b2bea536016a5a2ab36.png"},7624:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/sdk-spec1-0fc1e69146786bac14fc7e1c46cdafb0.png"},1984:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/sdk-spec2-88a86ad37017e594f259603b83c9dcae.png"},9770:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/sdk-spec3-18c24f427918ab7645cabeb636199c02.png"},1829:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/sdk-spec4-9cbaff59435b913d123798d46a4aa9b9.png"},204:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/sdk-spec5-e20d551aa6775a125bd628694d461a61.png"},887:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/sdk-spec6-d7f3ec9454fd9e77a94efa8a4558f731.png"},5102:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/sdk-spec7-a0c30418e1e40e631469eb8eb6bfc2dd.png"},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>d});var i=n(6540);const a={},s=i.createContext(a);function r(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);
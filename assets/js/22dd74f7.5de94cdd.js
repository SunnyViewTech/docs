"use strict";(self.webpackChunkmy_website_en_2=self.webpackChunkmy_website_en_2||[]).push([[1567],{55226:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Dollars MONO","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Read Me First","href":"/Dollars-MONO/readmefirst","docId":"Dollars-MONO/readmefirst","unlisted":false},{"type":"link","label":"Motion Capture Mode","href":"/Dollars-MONO/mode","docId":"Dollars-MONO/mode","unlisted":false},{"type":"link","label":"Calibration","href":"/Dollars-MONO/calibration","docId":"Dollars-MONO/calibration","unlisted":false},{"type":"link","label":"Motion Capture Sensitivity","href":"/Dollars-MONO/sensitivity","docId":"Dollars-MONO/sensitivity","unlisted":false},{"type":"link","label":"Motion Capture Tolerance","href":"/Dollars-MONO/tolerance","docId":"Dollars-MONO/tolerance","unlisted":false},{"type":"link","label":"Enhanced Mode","href":"/Dollars-MONO/enhanced","docId":"Dollars-MONO/enhanced","unlisted":false},{"type":"link","label":"Facial Capture Modules","href":"/Dollars-MONO/facialcap-module","docId":"Dollars-MONO/facialcap-module","unlisted":false},{"type":"link","label":"Activate the NVIS Module","href":"/Dollars-MONO/nvis","docId":"Dollars-MONO/nvis","unlisted":false},{"type":"link","label":"Facial Capture Settings","href":"/Dollars-MONO/facialcap","docId":"Dollars-MONO/facialcap","unlisted":false},{"type":"link","label":"Recording BVH Files","href":"/Dollars-MONO/bvh","docId":"Dollars-MONO/bvh","unlisted":false},{"type":"link","label":"Using Virtual Camera as Input","href":"/Dollars-MONO/virtualcam","docId":"Dollars-MONO/virtualcam","unlisted":false},{"type":"link","label":"Sharing the Camera","href":"/Dollars-MONO/sharecam","docId":"Dollars-MONO/sharecam","unlisted":false},{"type":"link","label":"Stream","href":"/Dollars-MONO/engines","docId":"Dollars-MONO/engines","unlisted":false},{"type":"link","label":"Error Messages","href":"/Dollars-MONO/mono-errors","docId":"Dollars-MONO/mono-errors","unlisted":false},{"type":"link","label":"FAQ","href":"/mono-faq","docId":"Dollars-MONO/mono-faq","unlisted":false},{"type":"link","label":"Start Using MONO SDK","href":"/sdk","docId":"Dollars-MONO/sdk","unlisted":false},{"type":"link","label":"MONO SDK Guide","href":"/sdk-guide","docId":"Dollars-MONO/sdk_guide","unlisted":false},{"type":"link","label":"Archive","href":"/Dollars-MONO/archive","docId":"Dollars-MONO/archive","unlisted":false}],"href":"/category/dollars-mono"},{"type":"category","label":"Dollars DEEP","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Read Me First","href":"/Dollars-DEEP/readmefirst","docId":"Dollars-DEEP/readmefirst","unlisted":false},{"type":"link","label":"Switching Runtime Libraries","href":"/Dollars-DEEP/lilbraries","docId":"Dollars-DEEP/lilbraries","unlisted":false},{"type":"link","label":"Connecting Femto Bolt","href":"/Dollars-DEEP/femto","docId":"Dollars-DEEP/femto","unlisted":false},{"type":"link","label":"Camera Placement and Settings","href":"/Dollars-DEEP/placement","docId":"Dollars-DEEP/placement","unlisted":false},{"type":"link","label":"Motion Capture Mode","href":"/Dollars-DEEP/mode","docId":"Dollars-DEEP/mode","unlisted":false},{"type":"link","label":"Calibration","href":"/Dollars-DEEP/calibration","docId":"Dollars-DEEP/calibration","unlisted":false},{"type":"link","label":"FAQ","href":"/deep-faq","docId":"Dollars-DEEP/deep-faq","unlisted":false},{"type":"link","label":"Archive","href":"/Dollars-DEEP/archive","docId":"Dollars-DEEP/archive","unlisted":false},{"type":"category","label":"Dollars DEEP Lite","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Difference from DEEP","href":"/Dollars-DEEP/Dollars-DEEP-Lite/difference","docId":"Dollars-DEEP/Dollars-DEEP-Lite/difference","unlisted":false},{"type":"link","label":"Installation and Switching Runtime Libraries","href":"/Dollars-DEEP/Dollars-DEEP-Lite/libraries","docId":"Dollars-DEEP/Dollars-DEEP-Lite/libraries","unlisted":false},{"type":"link","label":"Gesture Recognition","href":"/Dollars-DEEP/Dollars-DEEP-Lite/gestures","docId":"Dollars-DEEP/Dollars-DEEP-Lite/gestures","unlisted":false},{"type":"link","label":"Using DEEP Lite in Unreal Engine","href":"/Dollars-DEEP/Dollars-DEEP-Lite/ue","docId":"Dollars-DEEP/Dollars-DEEP-Lite/ue","unlisted":false},{"type":"link","label":"VFX Samples","href":"/vfx-samples","docId":"Dollars-DEEP/Dollars-DEEP-Lite/vfx_samples","unlisted":false}],"href":"/category/dollars-deep-lite"}],"href":"/category/dollars-deep"},{"type":"category","label":"Dollars VIVA","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Supported Configurations","href":"/Dollars-VIVA/devices","docId":"Dollars-VIVA/devices","unlisted":false},{"type":"link","label":"Before Started","href":"/Dollars-VIVA/beforeuse","docId":"Dollars-VIVA/beforeuse","unlisted":false},{"type":"link","label":"Wearing the Trackers","href":"/Dollars-VIVA/getstarted","docId":"Dollars-VIVA/getstarted","unlisted":false},{"type":"link","label":"Get Started","href":"/Dollars-VIVA/calibration","docId":"Dollars-VIVA/calibration","unlisted":false},{"type":"link","label":"Common Calibration Issues","href":"/Dollars-VIVA/calibrationerror","docId":"Dollars-VIVA/calibrationerror","unlisted":false},{"type":"link","label":"Using an HMD for Motion Capture","href":"/Dollars-VIVA/hmd","docId":"Dollars-VIVA/hmd","unlisted":false},{"type":"link","label":"Room Setup Using Only VIVE Tracker","href":"/Dollars-VIVA/roomsetup","docId":"Dollars-VIVA/roomsetup","unlisted":false},{"type":"link","label":"Record BVH Files","href":"/Dollars-VIVA/bvh","docId":"Dollars-VIVA/bvh","unlisted":false},{"type":"link","label":"FAQ","href":"/viva-faq","docId":"Dollars-VIVA/viva-faq","unlisted":false}],"href":"/category/dollars-viva"},{"type":"category","label":"Dollars EGAO","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Facial Capture","href":"/Dollars-EGAO/facialcap","docId":"Dollars-EGAO/facialcap","unlisted":false},{"type":"link","label":"FAQ","href":"/egao-faq","docId":"Dollars-EGAO/egao-faq","unlisted":false}],"href":"/category/dollars-egao"},{"type":"category","label":"Dollars NVIS","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Get Started","href":"/Dollars-NVIS/getstarted","docId":"Dollars-NVIS/getstarted","unlisted":false},{"type":"link","label":"Settings","href":"/Dollars-NVIS/settings","docId":"Dollars-NVIS/settings","unlisted":false},{"type":"link","label":"Facial Capture Parameters","href":"/Dollars-NVIS/facialcap","docId":"Dollars-NVIS/facialcap","unlisted":false}],"href":"/category/dollars-nvis"},{"type":"category","label":"Dollars LINK","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Get Started","href":"/Dollars-LINK/getstarted","docId":"Dollars-LINK/getstarted","unlisted":false},{"type":"link","label":"Connecting to iClone","href":"/connect-to-iclone","docId":"Dollars-LINK/link-iclone","unlisted":false},{"type":"link","label":"FAQ","href":"/link-faq","docId":"Dollars-LINK/link-faq","unlisted":false}],"href":"/category/dollars-link"},{"type":"category","label":"Dollars MOTS","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Get Started","href":"/Dollars-MOTS/getstarted","docId":"Dollars-MOTS/getstarted","unlisted":false},{"type":"link","label":"Settings","href":"/Dollars-MOTS/settings","docId":"Dollars-MOTS/settings","unlisted":false},{"type":"link","label":"Record BVH Files","href":"/Dollars-MOTS/bvh","docId":"Dollars-MOTS/bvh","unlisted":false},{"type":"link","label":"Using the API","href":"/Dollars-MOTS/api","docId":"Dollars-MOTS/api","unlisted":false},{"type":"link","label":"FAQ","href":"/mots-faq","docId":"Dollars-MOTS/mots-faq","unlisted":false}],"href":"/category/dollars-mots"},{"type":"category","label":"Dollars SOMA","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Get Started","href":"/Dollars-SOMA/getstarted","docId":"Dollars-SOMA/getstarted","unlisted":false},{"type":"link","label":"Settings","href":"/Dollars-SOMA/settings","docId":"Dollars-SOMA/settings","unlisted":false},{"type":"link","label":"Hand Gestures","href":"/Dollars-SOMA/handgestures","docId":"Dollars-SOMA/handgestures","unlisted":false},{"type":"link","label":"Body Gestures","href":"/Dollars-SOMA/gestures","docId":"Dollars-SOMA/gestures","unlisted":false},{"type":"link","label":"Using with Other Products","href":"/Dollars-SOMA/other_programs","docId":"Dollars-SOMA/other_programs","unlisted":false},{"type":"link","label":"FAQ","href":"/soma-faq","docId":"Dollars-SOMA/soma-faq","unlisted":false}],"href":"/category/dollars-soma"},{"type":"category","label":"Integration","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"UnrealEngine","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Get Started","href":"/ue-getstarted","docId":"Integration/UnrealEngine/ue_getstarted","unlisted":false},{"type":"link","label":"Using Your Characters","href":"/ue-characters","docId":"Integration/UnrealEngine/ue_characters","unlisted":false},{"type":"link","label":"Facial Capture Using LiveLinkFace Method","href":"/ue-livelinkface","docId":"Integration/UnrealEngine/livelinkface","unlisted":false},{"type":"link","label":"Tracking Status","href":"/ue-visibility","docId":"Integration/UnrealEngine/ue_visibility","unlisted":false},{"type":"link","label":"Gesture Recognition","href":"/ue-gestures","docId":"Integration/UnrealEngine/ue_gestures","unlisted":false},{"type":"link","label":"Multi-person Motion Capture","href":"/ue-multiplayer","docId":"Integration/UnrealEngine/ue_multiplayer","unlisted":false},{"type":"link","label":"Advanced Topics","href":"/ue-advanced","docId":"Integration/UnrealEngine/ue_advanced","unlisted":false},{"type":"link","label":"Multiplayer Networked MoCap","href":"/ue-network","docId":"Integration/UnrealEngine/ue_network","unlisted":false},{"type":"link","label":"FAQ","href":"/ue-faq","docId":"Integration/UnrealEngine/ue-faq","unlisted":false},{"type":"link","label":"UE Samples","href":"/ue-samples","docId":"Integration/UnrealEngine/ue_samples","unlisted":false}],"href":"/category/unrealengine"},{"type":"category","label":"Unity","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Unity","href":"/unity","docId":"Integration/Unity/unity","unlisted":false},{"type":"link","label":"Tracking Status","href":"/unity-visibility","docId":"Integration/Unity/unity_visibility","unlisted":false},{"type":"link","label":"Gesture Recognition","href":"/unity-gestures","docId":"Integration/Unity/unity_gestures","unlisted":false},{"type":"link","label":"Multi-person Motion Capture","href":"/unity-multiplayer","docId":"Integration/Unity/unity_multiplayer","unlisted":false},{"type":"link","label":"FAQ","href":"/unity-faq","docId":"Integration/Unity/unity-faq","unlisted":false},{"type":"link","label":"Unity Samples","href":"/unity-samples","docId":"Integration/Unity/unity_samples","unlisted":false}],"href":"/category/unity"},{"type":"category","label":"Blender","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Video Tutorials","href":"/blender","docId":"Integration/Blender/Blender","unlisted":false},{"type":"link","label":"VRM Facial Cap","href":"/blender-vrm-facecap","docId":"Integration/Blender/vrm-facecap","unlisted":false},{"type":"link","label":"non-VRM Facial Cap","href":"/blender-facecap","docId":"Integration/Blender/facecap","unlisted":false}],"href":"/category/blender"},{"type":"category","label":"iClone and CTA","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Using the Plugin","href":"/iClone","docId":"Integration/iClone/plugin","unlisted":false},{"type":"link","label":"Video Tutorials","href":"/iClone-tutorials","docId":"Integration/iClone/iClone","unlisted":false}],"href":"/category/iclone-and-cta"},{"type":"link","label":"Other DCC Software","href":"/dcc/others","docId":"Integration/others","unlisted":false},{"type":"link","label":"VRChat","href":"/vrchat","docId":"Integration/vrchat","unlisted":false},{"type":"link","label":"Use with Other Tracking Devices","href":"/otherdevices","docId":"Integration/gloves","unlisted":false}],"href":"/category/integration"},{"type":"link","label":"FAQ","href":"/faq","docId":"faq","unlisted":false}]},"docs":{"Dollars-DEEP/archive":{"id":"Dollars-DEEP/archive","title":"Archive","description":"Mar 6th, 2024","sidebar":"tutorialSidebar"},"Dollars-DEEP/calibration":{"id":"Dollars-DEEP/calibration","title":"Calibration","description":"When you launch Dollars DEEP, the motion capture avatar may appear anywhere on the screen depending on the position of your camera.","sidebar":"tutorialSidebar"},"Dollars-DEEP/deep-faq":{"id":"Dollars-DEEP/deep-faq","title":"FAQ","description":"Lower Body Does Not Move","sidebar":"tutorialSidebar"},"Dollars-DEEP/Dollars-DEEP-Lite/difference":{"id":"Dollars-DEEP/Dollars-DEEP-Lite/difference","title":"Difference from DEEP","description":"Dollars DEEP Lite is a lower-tier version of DEEP.","sidebar":"tutorialSidebar"},"Dollars-DEEP/Dollars-DEEP-Lite/gestures":{"id":"Dollars-DEEP/Dollars-DEEP-Lite/gestures","title":"Gesture Recognition","description":"Dollars DEEP Lite currently supports recognition of the following gestures,","sidebar":"tutorialSidebar"},"Dollars-DEEP/Dollars-DEEP-Lite/libraries":{"id":"Dollars-DEEP/Dollars-DEEP-Lite/libraries","title":"Installation and Switching Runtime Libraries","description":"Download","sidebar":"tutorialSidebar"},"Dollars-DEEP/Dollars-DEEP-Lite/ue":{"id":"Dollars-DEEP/Dollars-DEEP-Lite/ue","title":"Using DEEP Lite in Unreal Engine","description":"To use DEEP Lite in Unreal Engine, you need to download the Unreal Engine plugin and the [UE4 Mannequin blueprint](https://kilimanjaro.dollarsmocap.com/DEEPLite/Dollars_UE4Mannequin.zip","sidebar":"tutorialSidebar"},"Dollars-DEEP/Dollars-DEEP-Lite/vfx_samples":{"id":"Dollars-DEEP/Dollars-DEEP-Lite/vfx_samples","title":"VFX Samples","description":"BodyFX","sidebar":"tutorialSidebar"},"Dollars-DEEP/femto":{"id":"Dollars-DEEP/femto","title":"Connecting Femto Bolt","description":"Before using DEEP, please follow these steps to ensure that Femto Bolt is properly connected and can perform skeletal recognition.","sidebar":"tutorialSidebar"},"Dollars-DEEP/lilbraries":{"id":"Dollars-DEEP/lilbraries","title":"Switching Runtime Libraries","description":"By default, Dollars DEEP launches with runtime libraries for Azure Kinect. If you are using Femto Bolt, you will need to switch the runtime library to support it. To do this, run the Install Femto Bolt Libraries.bat file shown in the image below before starting the program.","sidebar":"tutorialSidebar"},"Dollars-DEEP/mode":{"id":"Dollars-DEEP/mode","title":"Motion Capture Mode","description":"Dollar DEEP offers two motion capture modes,","sidebar":"tutorialSidebar"},"Dollars-DEEP/placement":{"id":"Dollars-DEEP/placement","title":"Camera Placement and Settings","description":"Orientation","sidebar":"tutorialSidebar"},"Dollars-DEEP/readmefirst":{"id":"Dollars-DEEP/readmefirst","title":"Read Me First","description":"The important points applicable to Dollars MONO also apply to Dollars DEEP, so we reiterate them here.","sidebar":"tutorialSidebar"},"Dollars-EGAO/egao-faq":{"id":"Dollars-EGAO/egao-faq","title":"FAQ","description":"FBX Export Supports","sidebar":"tutorialSidebar"},"Dollars-EGAO/facialcap":{"id":"Dollars-EGAO/facialcap","title":"Facial Capture","description":"Dollars EGAO provides ARKit-compatible facial expression capture.","sidebar":"tutorialSidebar"},"Dollars-LINK/getstarted":{"id":"Dollars-LINK/getstarted","title":"Get Started","description":"You need an iPhone that supports FaceID, and you must install Live Link Face for facial capture.","sidebar":"tutorialSidebar"},"Dollars-LINK/link-faq":{"id":"Dollars-LINK/link-faq","title":"FAQ","description":"Occasional Lag During Facial Capturer","sidebar":"tutorialSidebar"},"Dollars-LINK/link-iclone":{"id":"Dollars-LINK/link-iclone","title":"Connecting to iClone","description":"Using the iClone Plugin","sidebar":"tutorialSidebar"},"Dollars-MONO/archive":{"id":"Dollars-MONO/archive","title":"Archive","description":"Mar 30th, 2025","sidebar":"tutorialSidebar"},"Dollars-MONO/bvh":{"id":"Dollars-MONO/bvh","title":"Recording BVH Files","description":"To start and stop recording a BVH file, simply press the button shown in the image.","sidebar":"tutorialSidebar"},"Dollars-MONO/calibration":{"id":"Dollars-MONO/calibration","title":"Calibration","description":"When positioning the camera, you may sometimes tilt it slightly to obtain a more comprehensive view of the person being captured.","sidebar":"tutorialSidebar"},"Dollars-MONO/engines":{"id":"Dollars-MONO/engines","title":"Stream","description":"You can enable or disable the streaming function in the options dialog.","sidebar":"tutorialSidebar"},"Dollars-MONO/enhanced":{"id":"Dollars-MONO/enhanced","title":"Enhanced Mode","description":"You can check the \\"Enhanced Mode\\" option in the Options window to achieve higher quality motion capture.","sidebar":"tutorialSidebar"},"Dollars-MONO/facialcap":{"id":"Dollars-MONO/facialcap","title":"Facial Capture Settings","description":"Dollars MONO provides ARKit-compatible facial expression capture.","sidebar":"tutorialSidebar"},"Dollars-MONO/facialcap-module":{"id":"Dollars-MONO/facialcap-module","title":"Facial Capture Modules","description":"Starting from version v.241128, MONO provides two facial capture modules: EGAO and NVIS. You can choose to use either module based on your needs in the settings.","sidebar":"tutorialSidebar"},"Dollars-MONO/mode":{"id":"Dollars-MONO/mode","title":"Motion Capture Mode","description":"Dollar MONO offers three motion capture modes,","sidebar":"tutorialSidebar"},"Dollars-MONO/mono-errors":{"id":"Dollars-MONO/mono-errors","title":"Error Messages","description":"When MONO encounters an error, an appropriate message will be displayed at the top of the program interface.","sidebar":"tutorialSidebar"},"Dollars-MONO/mono-faq":{"id":"Dollars-MONO/mono-faq","title":"FAQ","description":"Program Crashes on Startup","sidebar":"tutorialSidebar"},"Dollars-MONO/nvis":{"id":"Dollars-MONO/nvis","title":"Activate the NVIS Module","description":"If you have already purchased a MONO license, due to MONO running offline, the system will not automatically retrieve the information about your NVIS license after purchase.","sidebar":"tutorialSidebar"},"Dollars-MONO/readmefirst":{"id":"Dollars-MONO/readmefirst","title":"Read Me First","description":"Please ensure you have thoroughly read the content of this page before diving deeply into Dollars MONO.","sidebar":"tutorialSidebar"},"Dollars-MONO/sdk":{"id":"Dollars-MONO/sdk","title":"Start Using MONO SDK","description":"Start Using MONO SDK","sidebar":"tutorialSidebar"},"Dollars-MONO/sdk_guide":{"id":"Dollars-MONO/sdk_guide","title":"MONO SDK Guide","description":"Introduction","sidebar":"tutorialSidebar"},"Dollars-MONO/sensitivity":{"id":"Dollars-MONO/sensitivity","title":"Motion Capture Sensitivity","description":"You can adjust the motion capture sensitivity settings to achieve different results based on your needs.","sidebar":"tutorialSidebar"},"Dollars-MONO/sharecam":{"id":"Dollars-MONO/sharecam","title":"Sharing the Camera","description":"In this section, we\'ll show you how to use the OBS virtual camera to share the same camera across multiple applications. This allows you to perform motion capture in Dollars MONO while simultaneously capturing facial expressions in VTuber software like Animaze and VSeeFace.","sidebar":"tutorialSidebar"},"Dollars-MONO/tolerance":{"id":"Dollars-MONO/tolerance","title":"Motion Capture Tolerance","description":"The level of tolerance directly affects the performance of the motion capture system and can be adjusted based on the specific use case.","sidebar":"tutorialSidebar"},"Dollars-MONO/virtualcam":{"id":"Dollars-MONO/virtualcam","title":"Using Virtual Camera as Input","description":"Starting from v.230722, Dollars MONO supports OBS virtual camera. With the help of the virtual camera, the following scenarios can be achieved,","sidebar":"tutorialSidebar"},"Dollars-MOTS/api":{"id":"Dollars-MOTS/api","title":"Using the API","description":"You can use the OSC protocol to communicate with the MOTS frontend to control the character\'s movements.","sidebar":"tutorialSidebar"},"Dollars-MOTS/bvh":{"id":"Dollars-MOTS/bvh","title":"Record BVH Files","description":"You can record BVH files by pressing the button in the top left corner.","sidebar":"tutorialSidebar"},"Dollars-MOTS/getstarted":{"id":"Dollars-MOTS/getstarted","title":"Get Started","description":"Dollars MOTS consists of both frontend and backend components. You can start both simultaneously by clicking on the Dollars_MOTS.bat in the Dollars MOTS directory.","sidebar":"tutorialSidebar"},"Dollars-MOTS/mots-faq":{"id":"Dollars-MOTS/mots-faq","title":"FAQ","description":"Multi-Language Input Supports","sidebar":"tutorialSidebar"},"Dollars-MOTS/settings":{"id":"Dollars-MOTS/settings","title":"Settings","description":"You can open the program settings by clicking the gear icon.","sidebar":"tutorialSidebar"},"Dollars-NVIS/facialcap":{"id":"Dollars-NVIS/facialcap","title":"Facial Capture Parameters","description":"Similar to Dollars MONO, NVIS provides expression strength and dominant eye settings for adjustments.","sidebar":"tutorialSidebar"},"Dollars-NVIS/getstarted":{"id":"Dollars-NVIS/getstarted","title":"Get Started","description":"Before using Dollars NVIS, you need to download the corresponding package for your graphics card from the NVIDIA Broadcast Download Center and install it. Reboot is recommended after installation.","sidebar":"tutorialSidebar"},"Dollars-NVIS/settings":{"id":"Dollars-NVIS/settings","title":"Settings","description":"Similar to other Dollars MoCap products, you can select your camera and calibrate using the button in the upper left corner.","sidebar":"tutorialSidebar"},"Dollars-SOMA/gestures":{"id":"Dollars-SOMA/gestures","title":"Body Gestures","description":"SOMA currently supports recognition of the following body gestures.","sidebar":"tutorialSidebar"},"Dollars-SOMA/getstarted":{"id":"Dollars-SOMA/getstarted","title":"Get Started","description":"When first launched, the application will activate your device\'s primary camera. You\'ll be able to see recognized hand gestures displayed intuitively on screen, while detected body postures will be visualized in the upper portion of the display.","sidebar":"tutorialSidebar"},"Dollars-SOMA/handgestures":{"id":"Dollars-SOMA/handgestures","title":"Hand Gestures","description":"SOMA currently supports recognition of the following gestures.","sidebar":"tutorialSidebar"},"Dollars-SOMA/other_programs":{"id":"Dollars-SOMA/other_programs","title":"Using with Other Products","description":"Shared Camera","sidebar":"tutorialSidebar"},"Dollars-SOMA/settings":{"id":"Dollars-SOMA/settings","title":"Settings","description":"You can click the gear button to open program settings.","sidebar":"tutorialSidebar"},"Dollars-SOMA/soma-faq":{"id":"Dollars-SOMA/soma-faq","title":"FAQ","description":"How to add custom gestures\uff1f","sidebar":"tutorialSidebar"},"Dollars-VIVA/beforeuse":{"id":"Dollars-VIVA/beforeuse","title":"Before Started","description":"During the room setup stage in SteamVR, please make sure that the forward direction of SteamVR (the direction the arrow points to in the following image) aligns with the direction the motion capture actor is facing.","sidebar":"tutorialSidebar"},"Dollars-VIVA/bvh":{"id":"Dollars-VIVA/bvh","title":"Record BVH Files","description":"You can record BVH files by pressing the button in the top left corner.","sidebar":"tutorialSidebar"},"Dollars-VIVA/calibration":{"id":"Dollars-VIVA/calibration","title":"Get Started","description":"Before starting motion capture, it is necessary to perform a calibration.","sidebar":"tutorialSidebar"},"Dollars-VIVA/calibrationerror":{"id":"Dollars-VIVA/calibrationerror","title":"Common Calibration Issues","description":"Here are some common calibration issues and their solutions.","sidebar":"tutorialSidebar"},"Dollars-VIVA/devices":{"id":"Dollars-VIVA/devices","title":"Supported Configurations","description":"Device Configurations Supported by VIVA","sidebar":"tutorialSidebar"},"Dollars-VIVA/getstarted":{"id":"Dollars-VIVA/getstarted","title":"Wearing the Trackers","description":"Before opening Dollars VIVA, it is recommended that you turn on the Trackers you are going to wear and ensure that each Tracker is being stably tracked on the SteamVR panel.","sidebar":"tutorialSidebar"},"Dollars-VIVA/hmd":{"id":"Dollars-VIVA/hmd","title":"Using an HMD for Motion Capture","description":"You can also use an HMD for motion capture.","sidebar":"tutorialSidebar"},"Dollars-VIVA/roomsetup":{"id":"Dollars-VIVA/roomsetup","title":"Room Setup Using Only VIVE Tracker","description":"In standard SteamVR room setup, both a headset and controllers are typically required. If the headset is unavailable, it can be simulated by modifying configuration files. However, if controllers are also absent, room setup cannot be completed as expected. In such cases, SteamVR defaults to using a base station as the origin of the tracking space, which can lead to significant limitations during use.","sidebar":"tutorialSidebar"},"Dollars-VIVA/viva-faq":{"id":"Dollars-VIVA/viva-faq","title":"FAQ","description":"Finger Tracking Supports","sidebar":"tutorialSidebar"},"faq":{"id":"faq","title":"FAQ","description":"- Dollars MONO","sidebar":"tutorialSidebar"},"Integration/Blender/Blender":{"id":"Integration/Blender/Blender","title":"Video Tutorials","description":"MoCap in Blender(Any File Formats)","sidebar":"tutorialSidebar"},"Integration/Blender/facecap":{"id":"Integration/Blender/facecap","title":"non-VRM Facial Cap","description":"For non-VRM files, you can achieve real-time facial capture using the LiveLinkFace streaming method and the help of third-party plugins.","sidebar":"tutorialSidebar"},"Integration/Blender/vrm-facecap":{"id":"Integration/Blender/vrm-facecap","title":"VRM Facial Cap","description":"Blender 3.0.0","sidebar":"tutorialSidebar"},"Integration/gloves":{"id":"Integration/gloves","title":"Use with Other Tracking Devices","description":"All Dollars products can be used with other tracking devices and the tracking results can be integrated in the game engines and DCC software.","sidebar":"tutorialSidebar"},"Integration/iClone/iClone":{"id":"Integration/iClone/iClone","title":"Video Tutorials","description":"iClone8 Facial & MoCap","sidebar":"tutorialSidebar"},"Integration/iClone/plugin":{"id":"Integration/iClone/plugin","title":"Using the Plugin","description":"Download and Install Dollars MoCap Plugin","sidebar":"tutorialSidebar"},"Integration/others":{"id":"Integration/others","title":"Other DCC Software","description":"Use Dollars MONO in Real-time with Animaze","sidebar":"tutorialSidebar"},"Integration/Unity/unity":{"id":"Integration/Unity/unity","title":"Unity","description":"Streaming to Unity","sidebar":"tutorialSidebar"},"Integration/Unity/unity_gestures":{"id":"Integration/Unity/unity_gestures","title":"Gesture Recognition","description":"The following Dollars MoCap products support sending gesture events to Unity,","sidebar":"tutorialSidebar"},"Integration/Unity/unity_multiplayer":{"id":"Integration/Unity/unity_multiplayer","title":"Multi-person Motion Capture","description":"You can run the Dollars MoCap program on multiple computers separately, and gather the motion capture results into the same Unity scene to achieve multi-character interaction.","sidebar":"tutorialSidebar"},"Integration/Unity/unity_samples":{"id":"Integration/Unity/unity_samples","title":"Unity Samples","description":"Please open each project with the corresponding version of Unity.","sidebar":"tutorialSidebar"},"Integration/Unity/unity_visibility":{"id":"Integration/Unity/unity_visibility","title":"Tracking Status","description":"You can check the tracking status by retrieving the MoCapVisibility component from the DollarsMoCap prefab,","sidebar":"tutorialSidebar"},"Integration/Unity/unity-faq":{"id":"Integration/Unity/unity-faq","title":"FAQ","description":"Character Floating in Unity Scenes","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/livelinkface":{"id":"Integration/UnrealEngine/livelinkface","title":"Facial Capture Using LiveLinkFace Method","description":"The following Dollars MoCap products support facial capture using the LiveLinkFace method,","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/ue_advanced":{"id":"Integration/UnrealEngine/ue_advanced","title":"Advanced Topics","description":"We will show you the following topics,","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/ue_characters":{"id":"Integration/UnrealEngine/ue_characters","title":"Using Your Characters","description":"Motion Capture","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/ue_gestures":{"id":"Integration/UnrealEngine/ue_gestures","title":"Gesture Recognition","description":"The following Dollars MoCap products support sending gesture events to UE,","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/ue_getstarted":{"id":"Integration/UnrealEngine/ue_getstarted","title":"Get Started","description":"Unreal Engine Versions","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/ue_multiplayer":{"id":"Integration/UnrealEngine/ue_multiplayer","title":"Multi-person Motion Capture","description":"You can run the Dollars MoCap program on multiple computers separately, and gather the motion capture results into the same UE scene to achieve multi-character interaction.","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/ue_network":{"id":"Integration/UnrealEngine/ue_network","title":"Multiplayer Networked MoCap","description":"You can use Unreal Engine\'s Replication mechanism to achieve multiplayer networking across networks. This requires some modifications to the Dollars MoCap Unreal plugin. The following is a summary of these modifications using Unreal Engine\'s TPS (Third-Person Shooter) template as an example.","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/ue_samples":{"id":"Integration/UnrealEngine/ue_samples","title":"UE Samples","description":"For MetaHuman projects that don\u2019t rely on third-party plugins, right-click the .uproject file to upgrade to a higher version of Unreal Engine.","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/ue_visibility":{"id":"Integration/UnrealEngine/ue_visibility","title":"Tracking Status","description":"Tracking Status","sidebar":"tutorialSidebar"},"Integration/UnrealEngine/ue-faq":{"id":"Integration/UnrealEngine/ue-faq","title":"FAQ","description":"How to Combine Facial and Motion Capture","sidebar":"tutorialSidebar"},"Integration/vrchat":{"id":"Integration/vrchat","title":"VRChat","description":"The following Dollars MoCap product supports VRChat Full-Body Trackings,","sidebar":"tutorialSidebar"}}}}')}}]);